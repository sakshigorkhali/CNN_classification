{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62af7959-27ce-4436-be7d-0b64c9325e0d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h1>Augmenting Image Data in Python</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868b710-bdb7-4472-8cc7-4a1cb6c7f2d1",
   "metadata": {},
   "source": [
    "**Image augmentation** is a fundamental technique used in deep learning to artificially expand the diversity of a training dataset without actually collecting more data. By applying transformations such as rotations, flips, color adjustments, and adding noise, we can help our models generalize better to unseen data and reduce the risk of overfitting. In this tutorial, we’ll walk through several common augmentation techniques using a small sample from the famous **Kaggle Dogs vs. Cats** dataset.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will be able to:\n",
    "+ Understand the purpose and benefits of image augmentation.\n",
    "+ Apply geometric transformations like rotation, flipping, cropping, translation, shearing, and zooming.\n",
    "+ Perform color and intensity adjustments such as brightness, contrast, and hue shifts.\n",
    "+ Introduce noise and simulate occlusion through techniques like random erasing.\n",
    "\n",
    "## Prerequisites\n",
    "Before getting started, you should have:\n",
    "+ Basic knowledge of Python programming (e.g., functions, loops, packages).\n",
    "+ Familiarity with `NumPy` and `Matplotlib` for array manipulation and plotting.\n",
    "+ A Python environment (version 3.x) with `tensorflow`, `keras`, and `matplotlib` installed.\n",
    "+ Some exposure to image data and the concept of tensors is helpful, but not required.\n",
    "\n",
    "<hr>\n",
    "\n",
    "The images are stored in a directory called `\"train\"`, with a subdirectory for cat images called `\"cat\"`, and another for dog images called `\"dog\"`. Let's begin by importing and previewing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8767f5d-4f73-47a9-8db5-7fba20e9f24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b79e589e-fe1b-407a-b4bb-ee19237a7528",
   "metadata": {},
   "source": [
    "Next, we define a reusable helper function `display_images()` that will help us display multiple images side-by-side for quick visual inspection. This function will take a batch of images and display them in a single row, without axes clutter, along with a custom title above the row. We'll use this function throughout the tutorial to preview both original and augmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61712b-cdda-4d78-aaac-db9d7f23dbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bec1638e-2092-47d3-ae37-fe387804c592",
   "metadata": {},
   "source": [
    "Now, we preview the imported and resized images using the `display_images()` function we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e09cc2-5c41-406a-a9e9-5a2c6897a34c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9194199-c773-45e3-be45-d61219d42762",
   "metadata": {},
   "source": [
    "**Note:** If you see a message at the end of the output, it isn't an error. It's just TensorFlow’s way of saying \"I've delivered all the data you asked for.\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca78390-c752-4a9d-906b-99434b7560ad",
   "metadata": {},
   "source": [
    "## 1. Geometric Transformations\n",
    "We define a new augmentation pipeline using **Keras preprocessing layers** to apply geometric transformations that randomly flip, rotate, zoom, crop, and then resize images back to 180 by 180. Each time an image passes through this augmentation_layer, it will undergo a combination of random flips (horizontal and vertical), small rotations, slight zooms, and random cropping, all while maintaining consistent output size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7999a-ac50-447b-a839-4dced38f8950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c830dd43-fb16-4955-b31c-fea337b78fad",
   "metadata": {},
   "source": [
    "Let's apply the transformations and preview the augmented images to observe the effects of geometric transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cae3cb-765b-4718-afad-28a051789cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5c7b511-fc28-4366-8550-c70565b4dbac",
   "metadata": {},
   "source": [
    "The output shows how geometric transformations can easily introduce diversity into the image dataset without changing the label of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b754693-0a21-4af0-9a3f-8125f24f9ccf",
   "metadata": {},
   "source": [
    "## 2. Color and Intensity Transformations\n",
    "Next, we create a new augmentation pipeline that randomly adjusts the image’s brightness, contrast, saturation, and hue to simulate different lighting and color conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9c061-6082-45a7-b441-7b8c8aa245f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b29498a-2f83-444c-a967-5e47deaff9eb",
   "metadata": {},
   "source": [
    "Let’s display the images after applying the color and intensity transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f0c51c-c7ff-45a2-955f-a1d03d9b0acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2e68e6c-1f7a-44b6-add5-db01c7d9c09f",
   "metadata": {},
   "source": [
    "As you notice, some images are slightly brighter, darker, more saturated, or have slight color tints, mimicking lighting differences a model might encounter during deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a20416-412b-42f6-ae5c-1c270c2de842",
   "metadata": {},
   "source": [
    "## 3. Occlusion and Cutout\n",
    "Here, we introduce random erasing (cutout) by randomly covering portions of the images with rectangles filled with random pixel values or black pixels. Random erasing teaches a model to rely less on any specific part of an object and instead focus on overall context, which can improve resilience against occlusion in real-world settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46086333-1991-4277-9aa8-f2e8cce70f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b222bf0-e038-49fc-89e7-b09ec0f751bd",
   "metadata": {},
   "source": [
    "Now, let’s preview the images to see the effect of random erasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04176455-2cf1-4339-a6f9-203013ffbfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c27c2a5e-7d16-444f-97da-23d6f3d6b292",
   "metadata": {},
   "source": [
    "You can see that some parts of the images are randomly \"cut out\", appearing as missing patches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52bd674-4242-4a21-b901-d993324bb6df",
   "metadata": {},
   "source": [
    "## 4. Random Operations\n",
    "Finally, we apply a general-purpose augmentation strategy called `RandAugment`, which randomly selects and applies two operations from a list of possible augmentations with a specified intensity. This approach helps create highly varied datasets without needing to manually specify every transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89278337-7afc-4470-a516-bbd7db697315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eb38b08-45ed-4864-9940-0c465c2b190f",
   "metadata": {},
   "source": [
    "Let’s preview the images augmented using the random augmentation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd73c2-4def-4721-89c9-3720dd0624ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2170ec60-0575-40fd-a200-2839d03e6421",
   "metadata": {},
   "source": [
    "Since these are random augmentations, it's impossible to tell what results you'll get. However, you should see images with random variations due to the two operations chosen for each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0c6ab-e797-4829-a5b9-e80b570f1cd9",
   "metadata": {},
   "source": [
    "In this tutorial, we explored several popular image augmentation techniques that can drastically improve a model’s ability to generalize. By systematically applying geometric transformations, color adjustments, occlusions, and randomized augmentation pipelines, we make our models more resilient, better performing, and less prone to overfitting. However, it is important to note the following:\n",
    "+ Image augmentation should only be applied to training data, and not to validation or test data, as we want to evaluate our model on real images in order to assess its true performance.\n",
    "+ Image augmentation should also be plausible. It should not alter the image in a way that changes its class. For example, flipping an image of a traffic sign that points left to now point right, could change its meaning and may not be acceptable depending on the training objective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
