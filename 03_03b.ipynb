{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa0500b-84a1-41a1-92ad-2cbc1da5c049",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h1>Building a Convolutional Neural Network in Python using Keras</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53313a-5eb9-4cda-a09e-b16ebe4ee6e8",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs) are a powerful class of deep neural networks primarily used for processing image data. CNNs have proven extremely effective in image classification, object detection, and facial recognition tasks. In this tutorial, we'll build a CNN using Keras and TensorFlow to classify images from the CIFAR-10 dataset into 10 distinct categories.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will:\n",
    "+ Understand the basics of CNNs and their architecture.\n",
    "+ Learn how to preprocess image data for deep learning.\n",
    "+ Build a simple CNN using Keras and TensorFlow.\n",
    "+ Train and evaluate the CNN model.\n",
    "\n",
    "## Prerequisites\n",
    "Before we begin, ensure you have:\n",
    "\n",
    "+ Basic knowledge of Python programming (variables, functions, loops).\n",
    "+ Understanding of fundamental machine learning concepts.\n",
    "+ Python environment (version 3.x) with `tensorflow`, `keras`, and `matplotlib` installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f768317-f0c0-4981-9258-18b1453deb3b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Note:</b> For further insights into deep learning and model building with Keras and TensorFlow, consider exploring the LinkedIn Learning course <b>\"Deep Learning with Python: Foundations\"</b>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44d123-2592-4b6c-8d6a-13e8d7cef08e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>1. Import and Preprocess the Data</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5d744-3ae9-4522-b6a8-3a5355bf8f12",
   "metadata": {},
   "source": [
    "Let's start by importing the data and verifying that the shape is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f6c3d-cdf6-42c7-9f0d-1aa0c0f9988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print('Training data shape:', train_images.shape)\n",
    "print('Testing data shape:', test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483a322-9597-4405-b127-199f14877623",
   "metadata": {},
   "source": [
    "The **CIFAR-10** dataset is a well-known benchmark dataset commonly used to evaluate the performance of computer vision models, particularly convolutional neural networks (CNNs). It consists of 60,000 color images, each of dimensions 32 x 32 pixels with 3 color channels (RGB), divided into:\n",
    "+ 50,000 images for training.\n",
    "+ 10,000 images for testing (evaluation).\n",
    "\n",
    "Each image is assigned exactly one of ten distinct classes representing common objects - (0) Airplane, (1) Automobile, (2) Bird, (3) Cat, (4) Deer, (5) Dog, (6) Frog, (7) Horse, (8) Ship, and (9) Truck.\n",
    "\n",
    "Let's preview the first 10 images in the training set to get a sense of what they look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db20ec-3b78-4a0c-864f-bedabef8237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize = (15, 1))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(train_images[i])\n",
    "    ax.set_title(class_names[train_labels[i][0]])\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1d9b14-a3de-423b-bc8c-4b192d7c0db9",
   "metadata": {},
   "source": [
    "As you can see, the images are very low resolution and somewhat difficult to make out. They are 32 x 32 pixels in dimension. They weren't necessarily designed to be viewed on a high-resolution screen. However, we can tell what each image is by looking at the label.\n",
    "\n",
    "Pixel values in images range from 0 to 255. Deep learning models (such as CNNs) perform better when input values are scaled to a smaller range, typically between 0 and 1. To accommodate this, we convert the data type of the image pixels to float32 and normalize the values to fall within 0 and 1 by dividing them by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a4b30-94f8-4ff8-8cd7-9bf1cf2004b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48de349-1055-47de-93b2-4a657ef4c7c9",
   "metadata": {},
   "source": [
    "For labels, we'll use one-hot encoding. Each integer label (0-9) is converted to a binary vector with one \"hot\" (1) position indicating the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d757f3-6dac-4462-8425-0e9c253b66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef7798-c563-4da1-91f9-6e64732eabfc",
   "metadata": {},
   "source": [
    "Now, `train_labels` and `test_labels` are matrices of shape (50000, 10) and (10000, 10), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e9b52-e9ec-4254-bcf4-207d339ce3ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>2. Define the Model Architecture</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75d70f-ab9f-4e37-9184-22a60ad97ee7",
   "metadata": {},
   "source": [
    "First, we create a Sequential model. This is a linear stack of layers that simplifies the construction of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d8cf0-d63e-4c0d-bd33-01f79d5b1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9268c-8b3a-46e2-9a6f-4fc8098b2f3f",
   "metadata": {},
   "source": [
    "Next, we define the input shape of our data. The CIFAR-10 images have dimensions of 32 pixels by 32 pixels, with 3 color channels (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6642d2-71d9-4f00-b373-32fd2a244117",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.Input(shape = (32, 32, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc0a2cd-21c2-4112-b018-5b70e8ad9fc5",
   "metadata": {},
   "source": [
    "We add a convolutional layer (Conv2D) with:\n",
    "+ 32 filters: These filters detect various features (edges, textures, shapes) in the images.\n",
    "+ Kernel size (3 x 3): Defines the size of the window moving across the image to extract features.\n",
    "+ ReLU activation: Introduces non-linearity, allowing the CNN to learn more complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ec41c-797a-4ba3-b4ed-4c97c8e79202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model.add(layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb732e7-20c5-4859-85fb-5beee9166f5a",
   "metadata": {},
   "source": [
    "We add Batch Normalization to stabilize and speed up training by normalizing the layer inputs. This reduces internal covariate shift and allows the network to learn faster and more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf0968-b853-404d-91f6-b23152c3046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa26f9-07dd-41c6-984c-e39d38890b5c",
   "metadata": {},
   "source": [
    "We apply MaxPooling to reduce the spatial dimensions (width and height) of feature maps, summarizing the presence of features in patches of the image. Here, the pooling size of (2,2) halves the dimensions of the feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43d005-0aea-4769-9cbd-814302500150",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bdf85-5492-44b6-81df-cdc28520c754",
   "metadata": {},
   "source": [
    "A Dropout layer randomly turns off neurons during training (here, with a probability of 25%). This reduces the risk of overfitting by preventing the network from overly relying on specific neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc83e2-d92a-4a12-913d-4c6353d90d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dropout(rate = 0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fae5ae-6cf4-45db-b79d-c79aa0cf8339",
   "metadata": {},
   "source": [
    "We add a second convolutional block, similar to the first, but this time with 64 filters, followed again by Batch Normalization, MaxPooling, and Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399982d-8056-43b4-98f0-63f174b4a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(layers.Dropout(rate = 0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde674dc-fe3a-4b00-8b01-7f9145f8ba87",
   "metadata": {},
   "source": [
    "We introduce a third convolutional block with 128 filters, also followed by Batch Normalization, MaxPooling, and Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73315e-9c07-4f25-a23c-7ba9d0dc7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(layers.Dropout(rate = 0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e9882-23d3-4153-b04f-3bf110e7bc53",
   "metadata": {},
   "source": [
    "Before transitioning to the fully connected layers, we use a Flatten layer to reshape the three-dimensional feature maps into a one-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e38c8-9386-4214-b4f3-af61248fb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd441a3-b045-4a52-a573-f3b80ff6acc6",
   "metadata": {},
   "source": [
    "We add a fully connected Dense layer with 512 neurons and ReLU activation. This layer integrates and interprets features extracted by convolutional layers to make meaningful predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659256c-2fe6-4e54-a6b2-eff60a890c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(units = 512, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e37bb-4619-4efa-9243-aabbe0802fe8",
   "metadata": {},
   "source": [
    "Again, we apply Batch Normalization and Dropout to the fully connected layer to ensure stable training and reduce the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d607d84-69dd-478c-aaba-6f11a11e3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e84f03-c905-4aac-b791-bd36166980a8",
   "metadata": {},
   "source": [
    "Finally, we add an output layer with 10 neurons, corresponding to the ten classes in CIFAR-10. The softmax activation function converts the output into probabilities for each class, indicating the likelihood of the input image belonging to each of the 10 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f3d8b-b904-473d-95e8-3ba971013b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c94d0b-88a6-4953-a914-044e317b9314",
   "metadata": {},
   "source": [
    "Rather than adding each layer of the model one by one, we can also define the entire model at once as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683ccfb-3233-4a89-9fc7-d7f112fe5e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape = (32, 32, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    layers.Dropout(rate = 0.25),\n",
    "    \n",
    "    layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    layers.Dropout(rate = 0.25),\n",
    "    \n",
    "    layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    layers.Dropout(rate = 0.25),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units = 512, activation = 'relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(rate = 0.5),\n",
    "    layers.Dense(units = 10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55a732-7eb8-4662-9422-45f4bbad1088",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>3. Compile and Train the Model</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d444eb1-5aa0-4538-9c76-b20d08658aec",
   "metadata": {},
   "source": [
    "Before training, we compile the model by specifying the optimizer, loss function, and metrics. For multiclass classification, the `'categorical_crossentropy'` loss function is appropriate, and we include `'accuracy'` as a metric to gauge the percentage of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ddc3a-0b23-4253-89ad-c3ddb37e0924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d37162f3-558d-4e57-8ba5-9bddc2a907c8",
   "metadata": {},
   "source": [
    "To train the model, we call the `fit()` method and specify the training data, training labels, number of epochs (the number of times the model will iterate over the entire training dataset), batch size (the number of images processed before the model is updated), and validation split (the fraction of the training data to use for validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c048cc7-00c7-4391-89ae-5d8e3d9648a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb127100-6e8f-4183-861f-3a17da25ca5c",
   "metadata": {},
   "source": [
    "The `history` object returned by `model.fit()` contains the training and validation accuracy metrics for each epoch. Plotting this data helps us understand the model's performance across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1a053-f7a0-4f50-8265-594b2a5f69ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "933105eb-1c0d-42f6-ab9d-83ad1b70f4ff",
   "metadata": {},
   "source": [
    "The chart shows that training accuracy consistently improves and eventually plateaus near approximately 80%. This indicates the model learns effectively from the training data. The validation accuracy has fluctuations but generally follows the training accuracy trend, indicating the model generalizes reasonably well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125023a-858b-4272-bab5-33100cbf9db5",
   "metadata": {},
   "source": [
    "The `history` object returned by `model.fit()` also contains the training and validation loss metrics for each epoch. Plotting this data is also informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba733475-f708-4ac8-a0c9-ed396ae33243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d8d88af-fe95-4425-bd86-d2f63d9e69a3",
   "metadata": {},
   "source": [
    "The chart shows that training loss consistently decreases, signaling that the model steadily becomes better at correctly predicting labels for the training data. Validation loss also generally decreases over epochs, but with notable fluctuations at earlier epochs. This initial instability could result from the model initially struggling with unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87386276-cca7-4616-a685-5d8e75fa8279",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>4. Evaluate the Model</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b47f552-db33-49ae-9365-10a5dc0153f0",
   "metadata": {},
   "source": [
    "Finally, we can evaluate the model's accuracy against the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af8e9e-e70c-46ec-bb12-f4c1295b68d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09e20a7b-a75d-4ec0-a309-351aa3a5899c",
   "metadata": {},
   "source": [
    "The accuracy score provides an objective measurement of our modelâ€™s generalization ability (i.e., how well it classifies images it has never seen before)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
