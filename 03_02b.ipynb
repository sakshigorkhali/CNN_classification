{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa0500b-84a1-41a1-92ad-2cbc1da5c049",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h1>Building a Convolutional Neural Network in Python using Keras</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53313a-5eb9-4cda-a09e-b16ebe4ee6e8",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs) are a powerful class of deep neural networks primarily used for processing image data. CNNs have proven extremely effective in image classification, object detection, and facial recognition tasks. In this tutorial, we'll build a CNN using Keras and TensorFlow to classify images from the CIFAR-10 dataset into 10 distinct categories.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will:\n",
    "+ Understand the basics of CNNs and their architecture.\n",
    "+ Learn how to preprocess image data for deep learning.\n",
    "+ Build a simple CNN using Keras and TensorFlow.\n",
    "+ Train and evaluate the CNN model.\n",
    "\n",
    "## Prerequisites\n",
    "Before we begin, ensure you have:\n",
    "\n",
    "+ Basic knowledge of Python programming (variables, functions, loops).\n",
    "+ Understanding of fundamental machine learning concepts.\n",
    "+ Python environment (version 3.x) with `tensorflow`, `keras`, and `matplotlib` installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f768317-f0c0-4981-9258-18b1453deb3b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Note:</b> For further insights into deep learning and model building with Keras and TensorFlow, consider exploring the LinkedIn Learning course <b>\"Deep Learning with Python: Foundations\"</b>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44d123-2592-4b6c-8d6a-13e8d7cef08e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>1. Import and Preprocess the Data</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5d744-3ae9-4522-b6a8-3a5355bf8f12",
   "metadata": {},
   "source": [
    "Let's start by importing the data and verifying that the shape is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f6c3d-cdf6-42c7-9f0d-1aa0c0f9988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print('Training data shape:', train_images.shape)\n",
    "print('Testing data shape:', test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483a322-9597-4405-b127-199f14877623",
   "metadata": {},
   "source": [
    "The **CIFAR-10** dataset is a well-known benchmark dataset commonly used to evaluate the performance of computer vision models, particularly convolutional neural networks (CNNs). It consists of 60,000 color images, each of dimensions 32 x 32 pixels with 3 color channels (RGB), divided into:\n",
    "+ 50,000 images for training.\n",
    "+ 10,000 images for testing (evaluation).\n",
    "\n",
    "Each image is assigned exactly one of ten distinct classes representing common objects - (0) Airplane, (1) Automobile, (2) Bird, (3) Cat, (4) Deer, (5) Dog, (6) Frog, (7) Horse, (8) Ship, and (9) Truck.\n",
    "\n",
    "Let's preview the first 10 images in the training set to get a sense of what they look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db20ec-3b78-4a0c-864f-bedabef8237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize = (15, 1))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(train_images[i])\n",
    "    ax.set_title(class_names[train_labels[i][0]])\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1d9b14-a3de-423b-bc8c-4b192d7c0db9",
   "metadata": {},
   "source": [
    "As you can see, the images are very low resolution and somewhat difficult to make out. They are 32 x 32 pixels in dimension. They weren't necessarily designed to be viewed on a high-resolution screen. However, we can tell what each image is by looking at the label.\n",
    "\n",
    "Pixel values in images range from 0 to 255. Deep learning models (such as CNNs) perform better when input values are scaled to a smaller range, typically between 0 and 1. To accommodate this, we convert the data type of the image pixels to float32 and normalize the values to fall within 0 and 1 by dividing them by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a4b30-94f8-4ff8-8cd7-9bf1cf2004b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48de349-1055-47de-93b2-4a657ef4c7c9",
   "metadata": {},
   "source": [
    "For labels, we'll use one-hot encoding. Each integer label (0-9) is converted to a binary vector with one \"hot\" (1) position indicating the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d757f3-6dac-4462-8425-0e9c253b66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef7798-c563-4da1-91f9-6e64732eabfc",
   "metadata": {},
   "source": [
    "Now, `train_labels` and `test_labels` are matrices of shape (50000, 10) and (10000, 10), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e9b52-e9ec-4254-bcf4-207d339ce3ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>2. Define the Model Architecture</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75d70f-ab9f-4e37-9184-22a60ad97ee7",
   "metadata": {},
   "source": [
    "First, we create a Sequential model. This is a linear stack of layers that simplifies the construction of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d8cf0-d63e-4c0d-bd33-01f79d5b1021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35f9268c-8b3a-46e2-9a6f-4fc8098b2f3f",
   "metadata": {},
   "source": [
    "Next, we define the input shape of our data. The CIFAR-10 images have dimensions of 32 pixels by 32 pixels, with 3 color channels (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6642d2-71d9-4f00-b373-32fd2a244117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bc0a2cd-21c2-4112-b018-5b70e8ad9fc5",
   "metadata": {},
   "source": [
    "We add a convolutional layer (Conv2D) with:\n",
    "+ 32 filters: These filters detect various features (edges, textures, shapes) in the images.\n",
    "+ Kernel size (3 x 3): Defines the size of the window moving across the image to extract features.\n",
    "+ ReLU activation: Introduces non-linearity, allowing the CNN to learn more complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ec41c-797a-4ba3-b4ed-4c97c8e79202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecb732e7-20c5-4859-85fb-5beee9166f5a",
   "metadata": {},
   "source": [
    "We add Batch Normalization to stabilize and speed up training by normalizing the layer inputs. This reduces internal covariate shift and allows the network to learn faster and more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf0968-b853-404d-91f6-b23152c3046e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6faa26f9-07dd-41c6-984c-e39d38890b5c",
   "metadata": {},
   "source": [
    "We apply MaxPooling to reduce the spatial dimensions (width and height) of feature maps, summarizing the presence of features in patches of the image. Here, the pooling size of (2,2) halves the dimensions of the feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43d005-0aea-4769-9cbd-814302500150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "840bdf85-5492-44b6-81df-cdc28520c754",
   "metadata": {},
   "source": [
    "A Dropout layer randomly turns off neurons during training (here, with a probability of 25%). This reduces the risk of overfitting by preventing the network from overly relying on specific neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc83e2-d92a-4a12-913d-4c6353d90d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47fae5ae-6cf4-45db-b79d-c79aa0cf8339",
   "metadata": {},
   "source": [
    "We add a second convolutional block, similar to the first, but this time with 64 filters, followed again by Batch Normalization, MaxPooling, and Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399982d-8056-43b4-98f0-63f174b4a0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dde674dc-fe3a-4b00-8b01-7f9145f8ba87",
   "metadata": {},
   "source": [
    "We introduce a third convolutional block with 128 filters, also followed by Batch Normalization, MaxPooling, and Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73315e-9c07-4f25-a23c-7ba9d0dc7629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "013e9882-23d3-4153-b04f-3bf110e7bc53",
   "metadata": {},
   "source": [
    "Before transitioning to the fully connected layers, we use a Flatten layer to reshape the three-dimensional feature maps into a one-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e38c8-9386-4214-b4f3-af61248fb5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bd441a3-b045-4a52-a573-f3b80ff6acc6",
   "metadata": {},
   "source": [
    "We add a fully connected Dense layer with 512 neurons and ReLU activation. This layer integrates and interprets features extracted by convolutional layers to make meaningful predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659256c-2fe6-4e54-a6b2-eff60a890c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b7e37bb-4619-4efa-9243-aabbe0802fe8",
   "metadata": {},
   "source": [
    "Again, we apply Batch Normalization and Dropout to the fully connected layer to ensure stable training and reduce the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d607d84-69dd-478c-aaba-6f11a11e3ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e84f03-c905-4aac-b791-bd36166980a8",
   "metadata": {},
   "source": [
    "Finally, we add an output layer with 10 neurons, corresponding to the ten classes in CIFAR-10. The softmax activation function converts the output into probabilities for each class, indicating the likelihood of the input image belonging to each of the 10 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f3d8b-b904-473d-95e8-3ba971013b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22c94d0b-88a6-4953-a914-044e317b9314",
   "metadata": {},
   "source": [
    "Rather than adding each layer of the model one by one, we can also define the entire model at once as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683ccfb-3233-4a89-9fc7-d7f112fe5e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
